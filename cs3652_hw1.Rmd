---
title: "DSII_Homework1"
author: "Chirag Shah"
date: '2019-02-25'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(caret)
library(boot)
library(tidyverse)
library(glmnet)
library(ISLR)
library(pls)
```

a) Fit a linear model using least squares on the training data and calculate the mean square error using the test data. 

```{r}
train_data <- read_csv(file = "./solubility_train.csv") 
test_data <- read_csv(file = "./solubility_test.csv")
```

Creating a linear model with the training data with Solubility as the outcome. 

```{r}
linear_train <- lm(Solubility~., data = train_data)

summary(linear_train)
```


```{r}
pred <- predict(linear_train, newdata = test_data)

#Calculating Mean Squared Error on the test data
MSE <- mean((test_data$Solubility - pred)^2)

print(MSE)
```

The mean squared error using the test data is 0.5558898. 

b) Fit a ridge regression model on the training data with lambda chosen by cross-validation. Report the test error. 

```{r}
#For ridge regression, creating an x matrix and y vector for train and test sets
xtrain <- model.matrix(Solubility~.,train_data)[,-1]
ytrain <- train_data$Solubility
xtest <- model.matrix(Solubility~.,test_data)[,-1]
ytest <- test_data$Solubility

#Using cross-validation to choose lambda (the tuning parameter)
set.seed(123)
cv.out <- cv.glmnet(xtrain,ytrain,alpha = 0)
plot(cv.out)
```

```{r}
best_lambda <- cv.out$lambda.min

#Ridge regression model creation
model <- glmnet(xtrain, ytrain, alpha = 0,lambda = best_lambda)

#Printing out the model
model$beta
```

The lowest value of lambda, i.e. the best lambda, is 0.1478399

```{r}
#Fitting the above trainning model on test dataset 
pred2 <- predict(model, s = best_lambda, newx = xtest)

#Calculating Accuracy via MSE
MSE2 <- mean((pred2 - ytest)^2)

#Printing MSE
print(MSE2)
```

The mean squared error of the ridge regression using the cross validation approach is 0.51474. 

c) Fit a lasso model on the training data, with lambda chosed by cross-validation. Report the test error, along with the number of non-zero coefficient estimates. 

```{r}
#Using cross-validation to select lambda
set.seed(123)
cv.out3 <- cv.glmnet(xtrain, ytrain, alpha = 1)
plot(cv.out3)
```

```{r}
best_lambda3 <- cv.out3$lambda.min

#lasso regression model using training data 
model3 <- glmnet(xtrain, ytrain, alpha = 1, lambda = best_lambda3)

#Printing out the model
model3$beta
```

```{r}
#Fitting the above trainning model on the test dataset
pred3 <- predict(model3, s = best_lambda3, newx = xtest)

#Calculating Accuracy via MSE
MSE3 <- mean((pred3 - ytest)^2)

#Printing MSE
print(MSE3)
```

The mean squared error using the lasso regression is 0.4952673.

```{r}
#lasso coefficients
lasso_coef <- predict(model3, type = "coefficients", s = best_lambda3)[1:ncol(train_data),]

#non zero coefficients
length(lasso_coef[lasso_coef!= 0])

length(lasso_coef)
```

The number of non-zero coefficients including the intercept is 142. 

d) Fit a PCR model on the training data with M chosed by cross-validation. Report the test error, along with the value of M selected by cross-validation. 

```{r}
pcr.mod <- pcr(Solubility~.,
              data = train_data,
              scale = TRUE,
              validation = "CV")

summary(pcr.mod)
```

```{r}
ctrl1 <- trainControl(method = "repeatedcv", number = 10, repeats = 5)

set.seed(123)
pcr.fit <- train(xtrain, ytrain,
                 method = "pcr",
                 tuneLength = 228,
                 trControl = ctrl1,
                 preProc = c("center", "scale"))

trans <- preProcess(xtrain, method = c("center", "scale"))

predy2.pcr2 <- predict(pcr.fit$finalModel, newdata = predict(trans, xtest),
                       ncomp = pcr.fit$bestTune$ncomp)

MSE4 <- mean((predy2.pcr2 - ytest)^2)

print(MSE4)
```

```{r}
set.seed(123)

pcr.fit2 <- train(xtrain, ytrain,
                  method = "pcr",
                  tuneLength = 228,
                  trControl = ctrl1,
                  scale = TRUE)

predy2.pcr3 <- predict(pcr.fit2$finalModel, newdata = xtest,
                       ncomp = pcr.fit2$bestTune$ncomp)
```

```{r}
ggplot(pcr.fit, highlight = TRUE) + theme_bw()
```


```{r}
#Fitting training model on the test dataset with M=150 based on graph above.
pred4.pcr <- predict(pcr.mod, newdata = test_data, ncomp = 150)

#Calculating accuracy via MSE
MSE4 <- mean((pred4.pcr - ytest)^2)

#Printing MSE
print(MSE4)
```

The mean squared error of the pcr model is 0.5483713.
Based on the graph above, the M value selected by cross validation is 150. 

e) Briefly discuss the results obtained in (a)~(d)

Based on the results obtained, it seems that the lasso regression model has the lowest mean squared error, indicating that it is the best model. Thus at it's face value, it seems that this model is the best in terms of describing the change in the outcome given the change in it's predictors (compared to the simple linear regression, ridge regression, and PCR). The PCR model showed us that some of the components may be correlated an variance could be still kept low by reducing the number of components from 228 to 150. 